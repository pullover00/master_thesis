# -*- coding: utf-8 -*-
"""YOLOX Model training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hGycpLSGZgZVaxBhPflBn5XywIAlKfkS

# Install YOLOX Dependencies
"""

!pip install torch==1.10.2+cu102 torchvision==0.11.3+cu102 torchaudio===0.10.2+cu102 -f https://download.pytorch.org/whl/cu102/torch_stable.html

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/roboflow-ai/YOLOX.git
!pip install theano
# %cd YOLOX
!pip3 install -U pip && pip3 install -r requirements.txt
!pip3 install -v -e .  
!pip uninstall -y torch torchvision torchaudio
# May need to change in the future if Colab no longer uses CUDA 11.0
!pip install torch==1.10.2+cu102 torchvision==0.11.3+cu102 torchaudio===0.10.2+cu102 -f https://download.pytorch.org/whl/cu102/torch_stable.html
#!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html --use-deprecated=html5lib

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/roboflow-ai/YOLOX.git
# %cd YOLOX
!pip3 install -U pip && pip3 install -r requirements.txt
!pip3 install -v -e .  
!pip uninstall -y torch torchvision torchaudio
# May need to change in the future if Colab no longer uses CUDA 11.0
!pip3 install torch torchvision torchaudio

"""## Install Nvidia Apex"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
!git clone https://github.com/NVIDIA/apex
# %cd apex
!pip install -v --disable-pip-version-check --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./

"""## Install PyCocoTools"""

!pip3 install cython; pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'

"""# Download your Data

We'll download our dataset from Roboflow. Use the "**Pascal VOC**" export format.

To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/).

"""

#to get your roboflow code below please follow the link output by this cell
!pip -q install roboflow
from roboflow import Roboflow
rf = Roboflow(model_format="voc", notebook="yolox")

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="9LVR5sxe9UhaiEJe15c5")
project = rf.workspace().project("detection-pipe-rings")
dataset = project.version(2).download("voc")

# Commented out IPython magic to ensure Python compatibility.
# %cd YOLOX/
!ln -s /content/Detection-pipe-rings-2/train/ ./datasets/VOCdevkit

#!rm -rf "/content/YOLOX/YOLOX"

"""## Format Your Data Appropriately"""

# Commented out IPython magic to ensure Python compatibility.
# %mkdir "/content/YOLOX/datasets/VOCdevkit/VOC2007"
!python3 voc_txt.py "/content/YOLOX/datasets/VOCdevkit/"
# %mkdir "/content/YOLOX/datasets/VOCdevkit/VOC2012"
!cp -r "/content/YOLOX/datasets/VOCdevkit/VOC2007/." "/content/YOLOX/datasets/VOCdevkit/VOC2012"

"""## Change the Classes
Make sure you change the classes based on what your dataset. To ensure that the training process will function as intended, write the classes in lowercase with no whitespace.
"""

from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))

# Commented out IPython magic to ensure Python compatibility.
# ##REPLACE this cell with your classnames stripped of whitespace and lowercase
# %%writetemplate /content/YOLOX/yolox/data/datasets/voc_classes.py
# 
# VOC_CLASSES = (
#   "mpu",
#   "mpui",
#   "mpli"
# )

# Commented out IPython magic to ensure Python compatibility.
# ##REPLACE this cell with your classnames stripped of whitespace and lowercase
# %%writetemplate /content/YOLOX/yolox/data/datasets/coco_classes.py
# 
# COCO_CLASSES = (
#   "mpu",
#   "mpui",
#   "mpli"
# )

"""Set the number of classes you have in your dataset in te `NUM_CLASSES` variable"""

NUM_CLASSES = 3
!sed -i -e 's/self.num_classes = 20/self.num_classes = {NUM_CLASSES}/g' "/content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py"

"""# Download Pretrained Weights"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
!wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth
# %cd /content/YOLOX/

"""# Train the Model"""

!pip install yolox

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/YOLOX/

!python tools/train.py -f exps/example/yolox_voc/yolox_voc_s.py -d 1 -b 16 --fp16 -o -c /content/best_ckpt_opt.pth.tar

"""# Evaluate the Model

"""

MODEL_PATH = "/content/YOLOX/YOLOX_outputs/yolox_voc_s/best_ckpt.pth.tar"
!python3 tools/eval.py -n  yolox-s -c {MODEL_PATH} -b 10 -d 1 --conf 0.001 -f exps/example/yolox_voc/yolox_voc_s.py

"""# Test the Model
Make sure you replace the `TEST_IMAGE_PATH` variable with a test image from your dataset
"""



TEST_IMAGE_PATH = "/content/Detection-pipe-rings-1/test/11222021_104749_1_jpg.rf.64539858751b94fab9eaa24f4c299b38.jpg"
!python tools/demo.py image -f /content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py -c {MODEL_PATH} --path {TEST_IMAGE_PATH} --conf 0.25 --nms 0.45 --tsize 640 --save_result --device gpu

"""# Visualize the Predictions
Make sure you replace the `OUTPUT_IMAGE_PATH` with the respective path of the image output. This path can be found somewhere in the `YOLOX_outputs` folder

"""

from PIL import Image
OUTPUT_IMAGE_PATH = "/content/YOLOX/YOLOX_outputs/yolox_voc_s/vis_res/2022_01_21_18_10_15/11222021_104749_1_jpg.rf.64539858751b94fab9eaa24f4c299b38.jpg" 
Image.open(OUTPUT_IMAGE_PATH)

TEST_IMAGE_PATH2 = "/content/Detection-pipe-rings-1/test/11222021_154513_1_jpg.rf.5ade51c0f943c41febb5356daa4b2c1e.jpg"
!python tools/demo.py image -f /content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py -c {MODEL_PATH} --path {TEST_IMAGE_PATH2} --conf 0.25 --nms 0.45 --tsize 640 --save_result --device gpu
OUTPUT2 = "/content/YOLOX/YOLOX_outputs/yolox_voc_s/vis_res/2022_01_21_18_27_21/11222021_154513_1_jpg.rf.5ade51c0f943c41febb5356daa4b2c1e.jpg"
Image.open(OUTPUT2)

"""# Export Trained Weights for Future Inference

Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cp {MODEL_PATH} /content/gdrive/My\ Drive